# coding: utf-8

"""
    BlackFox

    No description provided (generated by Swagger Codegen https://github.com/swagger-api/swagger-codegen)  # noqa: E501

    OpenAPI spec version: v1
    
    Generated by: https://github.com/swagger-api/swagger-codegen.git
"""


import pprint
import re  # noqa: F401

import six

from blackfox.models.optimization_engine_config import OptimizationEngineConfig  # noqa: F401,E501
from blackfox.models.range import Range  # noqa: F401,E501


class KerasOptimizationConfig(object):
    """NOTE: This class is auto generated by the swagger code generator program.

    Do not edit the class manually.
    """

    """
    Attributes:
      swagger_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    swagger_types = {
        'dropout': 'Range',
        'batch_size': 'int',
        'dataset_id': 'str',
        'input_ranges': 'list[Range]',
        'output_ranges': 'list[Range]',
        'problem_type': 'str',
        'hidden_layer_count_range': 'Range',
        'neurons_per_layer': 'Range',
        'training_algorithms': 'list[str]',
        'activation_functions': 'list[str]',
        'max_epoch': 'int',
        'cross_validation': 'bool',
        'validation_split': 'float',
        'random_seed': 'int',
        'engine_config': 'OptimizationEngineConfig'
    }

    attribute_map = {
        'dropout': 'dropout',
        'batch_size': 'batchSize',
        'dataset_id': 'datasetId',
        'input_ranges': 'inputRanges',
        'output_ranges': 'outputRanges',
        'problem_type': 'problemType',
        'hidden_layer_count_range': 'hiddenLayerCountRange',
        'neurons_per_layer': 'neuronsPerLayer',
        'training_algorithms': 'trainingAlgorithms',
        'activation_functions': 'activationFunctions',
        'max_epoch': 'maxEpoch',
        'cross_validation': 'crossValidation',
        'validation_split': 'validationSplit',
        'random_seed': 'randomSeed',
        'engine_config': 'engineConfig'
    }

    def __init__(self, dropout=None, batch_size=None, dataset_id=None, input_ranges=None, output_ranges=None, problem_type=None, hidden_layer_count_range=None, neurons_per_layer=None, training_algorithms=None, activation_functions=None, max_epoch=None, cross_validation=None, validation_split=None, random_seed=None, engine_config=None):  # noqa: E501
        """KerasOptimizationConfig - a model defined in Swagger"""  # noqa: E501

        self._dropout = Range(min=0, max=25)
        self._batch_size = 32
        self._dataset_id = None
        self._input_ranges = None
        self._output_ranges = None
        self._hidden_layer_count_range = Range(min=1, max=15)
        self._neurons_per_layer = Range(min=1, max=10)
        self._training_algorithms = ["SGD", "RMSprop", "Adagrad",
                                     "Adadelta", "Adam", "Adamax", "Nadam"]
        self._activation_functions = ["SoftMax", "Elu", "Selu", "SoftPlus",
                                      "SoftSign", "ReLu", "TanH", "Sigmoid",
                                      "HardSigmoid", "Linear"]
        self._max_epoch = 3000
        self._cross_validation = False
        self._validation_split = 0.2
        self._random_seed = 300
        self._problem_type = 'Regression'
        self._engine_config = OptimizationEngineConfig()
        self.discriminator = None

        if dropout is not None:
            self.dropout = dropout
        if batch_size is not None:
            self.batch_size = batch_size
        if dataset_id is not None:
            self.dataset_id = dataset_id
        if input_ranges is not None:
            self.input_ranges = input_ranges
        if output_ranges is not None:
            self.output_ranges = output_ranges
        if problem_type is not None:
            self.problem_type = problem_type
        if hidden_layer_count_range is not None:
            self.hidden_layer_count_range = hidden_layer_count_range
        if neurons_per_layer is not None:
            self.neurons_per_layer = neurons_per_layer
        if training_algorithms is not None:
            self.training_algorithms = training_algorithms
        if activation_functions is not None:
            self.activation_functions = activation_functions
        if max_epoch is not None:
            self.max_epoch = max_epoch
        if cross_validation is not None:
            self.cross_validation = cross_validation
        if validation_split is not None:
            self.validation_split = validation_split
        if random_seed is not None:
            self.random_seed = random_seed
        if engine_config is not None:
            self.engine_config = engine_config

    @property
    def dropout(self):
        """Gets the dropout in percent.
        Min value: 0
        Max value: 100

        :return: The dropout of this KerasOptimizationConfig.  # noqa: E501
        :rtype: Range
        """
        return self._dropout

    @dropout.setter
    def dropout(self, dropout):
        """Sets the dropout of this KerasOptimizationConfig.


        :param dropout: The dropout of this KerasOptimizationConfig.  # noqa: E501
        :type: Range
        """

        self._dropout = dropout

    @property
    def batch_size(self):
        """Gets the batch_size of this KerasOptimizationConfig.  # noqa: E501


        :return: The batch_size of this KerasOptimizationConfig.  # noqa: E501
        :rtype: int
        """
        return self._batch_size

    @batch_size.setter
    def batch_size(self, batch_size):
        """Sets the batch_size of this KerasOptimizationConfig.


        :param batch_size: The batch_size of this KerasOptimizationConfig.  # noqa: E501
        :type: int
        """

        self._batch_size = batch_size

    @property
    def dataset_id(self):
        """Gets the dataset_id of this KerasOptimizationConfig.  # noqa: E501


        :return: The dataset_id of this KerasOptimizationConfig.  # noqa: E501
        :rtype: str
        """
        return self._dataset_id

    @dataset_id.setter
    def dataset_id(self, dataset_id):
        """Sets the dataset_id of this KerasOptimizationConfig.


        :param dataset_id: The dataset_id of this KerasOptimizationConfig.  # noqa: E501
        :type: str
        """

        self._dataset_id = dataset_id

    @property
    def input_ranges(self):
        """Gets the input_ranges of this KerasOptimizationConfig.  # noqa: E501


        :return: The input_ranges of this KerasOptimizationConfig.  # noqa: E501
        :rtype: list[Range]
        """
        return self._input_ranges

    @input_ranges.setter
    def input_ranges(self, input_ranges):
        """Sets the input_ranges of this KerasOptimizationConfig.


        :param input_ranges: The input_ranges of this KerasOptimizationConfig.  # noqa: E501
        :type: list[Range]
        """

        self._input_ranges = input_ranges

    @property
    def output_ranges(self):
        """Gets the output_ranges of this KerasOptimizationConfig.  # noqa: E501


        :return: The output_ranges of this KerasOptimizationConfig.  # noqa: E501
        :rtype: list[Range]
        """
        return self._output_ranges

    @output_ranges.setter
    def output_ranges(self, output_ranges):
        """Sets the output_ranges of this KerasOptimizationConfig.


        :param output_ranges: The output_ranges of this KerasOptimizationConfig.  # noqa: E501
        :type: list[Range]
        """

        self._output_ranges = output_ranges

    @property
    def problem_type(self):
        """Gets the problem_type of this KerasOptimizationConfig.  # noqa: E501


        :return: The problem_type of this KerasOptimizationConfig.  # noqa: E501
        :rtype: str
        """
        return self._problem_type

    @problem_type.setter
    def problem_type(self, problem_type):
        """Sets the problem_type of this KerasOptimizationConfig.


        :param problem_type: The problem_type of this KerasOptimizationConfig.  # noqa: E501
        :type: str
        """
        allowed_values = ["Regression", "BinaryClassification", "MultiClassClassification"]  # noqa: E501
        if problem_type not in allowed_values:
            raise ValueError(
                "Invalid value for `problem_type` ({0}), must be one of {1}"  # noqa: E501
                .format(problem_type, allowed_values)
            )

        self._problem_type = problem_type

    @property
    def hidden_layer_count_range(self):
        """Gets the hidden_layer_count_range of this KerasOptimizationConfig.  # noqa: E501


        :return: The hidden_layer_count_range of this KerasOptimizationConfig.  # noqa: E501
        :rtype: Range
        """
        return self._hidden_layer_count_range

    @hidden_layer_count_range.setter
    def hidden_layer_count_range(self, hidden_layer_count_range):
        """Sets the hidden_layer_count_range of this KerasOptimizationConfig.


        :param hidden_layer_count_range: The hidden_layer_count_range of this KerasOptimizationConfig.  # noqa: E501
        :type: Range
        """

        self._hidden_layer_count_range = hidden_layer_count_range

    @property
    def neurons_per_layer(self):
        """Gets the neurons_per_layer of this KerasOptimizationConfig.  # noqa: E501


        :return: The neurons_per_layer of this KerasOptimizationConfig.  # noqa: E501
        :rtype: Range
        """
        return self._neurons_per_layer

    @neurons_per_layer.setter
    def neurons_per_layer(self, neurons_per_layer):
        """Sets the neurons_per_layer of this KerasOptimizationConfig.


        :param neurons_per_layer: The neurons_per_layer of this KerasOptimizationConfig.  # noqa: E501
        :type: Range
        """

        self._neurons_per_layer = neurons_per_layer

    @property
    def training_algorithms(self):
        """Gets the training_algorithms of this KerasOptimizationConfig.  # noqa: E501


        :return: The training_algorithms of this KerasOptimizationConfig.  # noqa: E501
        :rtype: list[str]
        """
        return self._training_algorithms

    @training_algorithms.setter
    def training_algorithms(self, training_algorithms):
        """Sets the training_algorithms of this KerasOptimizationConfig.


        :param training_algorithms: The training_algorithms of this KerasOptimizationConfig.  # noqa: E501
        :type: list[str]
        """
        allowed_values = ["SGD", "RMSprop", "Adagrad", "Adadelta", "Adam", "Adamax", "Nadam"]  # noqa: E501
        if not set(training_algorithms).issubset(set(allowed_values)):
            raise ValueError(
                "Invalid values for `training_algorithms` [{0}], must be a subset of [{1}]"  # noqa: E501
                .format(", ".join(map(str, set(training_algorithms) - set(allowed_values))),  # noqa: E501
                        ", ".join(map(str, allowed_values)))
            )

        self._training_algorithms = training_algorithms

    @property
    def activation_functions(self):
        """Gets the activation_functions of this KerasOptimizationConfig.  # noqa: E501


        :return: The activation_functions of this KerasOptimizationConfig.  # noqa: E501
        :rtype: list[str]
        """
        return self._activation_functions

    @activation_functions.setter
    def activation_functions(self, activation_functions):
        """Sets the activation_functions of this KerasOptimizationConfig.


        :param activation_functions: The activation_functions of this KerasOptimizationConfig.  # noqa: E501
        :type: list[str]
        """
        allowed_values = ["SoftMax", "Elu", "Selu", "SoftPlus", "SoftSign", "ReLu", "TanH", "Sigmoid", "HardSigmoid", "Linear"]  # noqa: E501
        if not set(activation_functions).issubset(set(allowed_values)):
            raise ValueError(
                "Invalid values for `activation_functions` [{0}], must be a subset of [{1}]"  # noqa: E501
                .format(", ".join(map(str, set(activation_functions) - set(allowed_values))),  # noqa: E501
                        ", ".join(map(str, allowed_values)))
            )

        self._activation_functions = activation_functions

    @property
    def max_epoch(self):
        """Gets the max_epoch of this KerasOptimizationConfig.  # noqa: E501


        :return: The max_epoch of this KerasOptimizationConfig.  # noqa: E501
        :rtype: int
        """
        return self._max_epoch

    @max_epoch.setter
    def max_epoch(self, max_epoch):
        """Sets the max_epoch of this KerasOptimizationConfig.


        :param max_epoch: The max_epoch of this KerasOptimizationConfig.  # noqa: E501
        :type: int
        """

        self._max_epoch = max_epoch

    @property
    def cross_validation(self):
        """Gets the cross_validation of this KerasOptimizationConfig.  # noqa: E501


        :return: The cross_validation of this KerasOptimizationConfig.  # noqa: E501
        :rtype: bool
        """
        return self._cross_validation

    @cross_validation.setter
    def cross_validation(self, cross_validation):
        """Sets the cross_validation of this KerasOptimizationConfig.


        :param cross_validation: The cross_validation of this KerasOptimizationConfig.  # noqa: E501
        :type: bool
        """

        self._cross_validation = cross_validation

    @property
    def validation_split(self):
        """Gets the validation_split of this KerasOptimizationConfig.  # noqa: E501


        :return: The validation_split of this KerasOptimizationConfig.  # noqa: E501
        :rtype: float
        """
        return self._validation_split

    @validation_split.setter
    def validation_split(self, validation_split):
        """Sets the validation_split of this KerasOptimizationConfig.


        :param validation_split: The validation_split of this KerasOptimizationConfig.  # noqa: E501
        :type: float
        """

        self._validation_split = validation_split

    @property
    def random_seed(self):
        """Gets the random_seed of this KerasOptimizationConfig.  # noqa: E501


        :return: The random_seed of this KerasOptimizationConfig.  # noqa: E501
        :rtype: int
        """
        return self._random_seed

    @random_seed.setter
    def random_seed(self, random_seed):
        """Sets the random_seed of this KerasOptimizationConfig.


        :param random_seed: The random_seed of this KerasOptimizationConfig.  # noqa: E501
        :type: int
        """

        self._random_seed = random_seed

    @property
    def engine_config(self):
        """Gets the engine_config of this KerasOptimizationConfig.  # noqa: E501


        :return: The engine_config of this KerasOptimizationConfig.  # noqa: E501
        :rtype: OptimizationEngineConfig
        """
        return self._engine_config

    @engine_config.setter
    def engine_config(self, engine_config):
        """Sets the engine_config of this KerasOptimizationConfig.


        :param engine_config: The engine_config of this KerasOptimizationConfig.  # noqa: E501
        :type: OptimizationEngineConfig
        """

        self._engine_config = engine_config

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.swagger_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, KerasOptimizationConfig):
            return False

        return self.__dict__ == other.__dict__

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        return not self == other
