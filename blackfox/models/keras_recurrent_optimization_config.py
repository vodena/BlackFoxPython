# coding: utf-8

"""
    BlackFox

    No description provided (generated by Swagger Codegen https://github.com/swagger-api/swagger-codegen)  # noqa: E501

    OpenAPI spec version: v1
    
    Generated by: https://github.com/swagger-api/swagger-codegen.git
"""


import pprint
import re  # noqa: F401

import six

from blackfox.models.input_config import InputConfig  # noqa: F401,E501
from blackfox.models.range import Range  # noqa: F401,E501
from blackfox.models.recurrent_optimization_engine_config import RecurrentOptimizationEngineConfig  # noqa: F401,E501


class KerasRecurrentOptimizationConfig(object):
    """NOTE: This class is auto generated by the swagger code generator program.

    Do not edit the class manually.
    """

    """
    Attributes:
      swagger_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    swagger_types = {
        'dropout': 'Range',
        'batch_size': 'int',
        'recurrent_dropout': 'Range',
        'recurrent_output_count': 'int',
        'dataset_id': 'str',
        'inputs': 'list[InputConfig]',
        'output_ranges': 'list[Range]',
        'hidden_layer_count_range': 'Range',
        'neurons_per_layer': 'Range',
        'training_algorithms': 'list[str]',
        'activation_functions': 'list[str]',
        'recurrent_activation_functions': 'list[str]',
        'max_epoch': 'int',
        'validation_split': 'float',
        'random_seed': 'int',
        'recurrent_input_count_range': 'Range',
        'engine_config': 'RecurrentOptimizationEngineConfig'
    }

    attribute_map = {
        'dropout': 'dropout',
        'batch_size': 'batchSize',
        'recurrent_dropout': 'recurrentDropout',
        'recurrent_output_count': 'recurrentOutputCount',
        'dataset_id': 'datasetId',
        'inputs': 'inputs',
        'output_ranges': 'outputRanges',
        'hidden_layer_count_range': 'hiddenLayerCountRange',
        'neurons_per_layer': 'neuronsPerLayer',
        'training_algorithms': 'trainingAlgorithms',
        'activation_functions': 'activationFunctions',
        'recurrent_activation_functions': 'recurrentActivationFunctions',
        'max_epoch': 'maxEpoch',
        'validation_split': 'validationSplit',
        'random_seed': 'randomSeed',
        'recurrent_input_count_range': 'recurrentInputCountRange',
        'engine_config': 'engineConfig'
    }

    def __init__(self, dropout=Range(min=0, max=25),
        batch_size=32,
        recurrent_dropout=Range(min=0, max=25),
		recurrent_output_count=1, 
        dataset_id=None,
        inputs=None, output_ranges=None,
        hidden_layer_count_range=Range(min=1, max=5),
        neurons_per_layer=Range(min=1, max=500),
        training_algorithms=["SGD", "RMSprop", "Adagrad", "Adadelta", "Adam", "Adamax", "Nadam"],
        activation_functions=["SoftMax", "Elu", "Selu", "SoftPlus",
                                      "SoftSign", "ReLu", "TanH", "Sigmoid",
                                      "HardSigmoid", "Linear"],
        recurrent_activation_functions=["SoftMax", "Elu", "Selu", "SoftPlus",
                                      "SoftSign", "ReLu", "TanH", "Sigmoid",
                                      "HardSigmoid", "Linear"], 
        max_epoch=3000, validation_split=0.3, random_seed=300, 
        recurrent_input_count_range=Range(min=1, max=7), 
        engine_config=RecurrentOptimizationEngineConfig()
        ):  # noqa: E501
        """KerasRecurrentOptimizationConfig - a model defined in Swagger"""  # noqa: E501

        self._dropout = None
        self._batch_size = None
        self._recurrent_dropout = None
        self._recurrent_output_count = None
        self._dataset_id = None
        self._inputs = None
        self._output_ranges = None
        self._hidden_layer_count_range = None
        self._neurons_per_layer = None
        self._training_algorithms = None
        self._activation_functions = None
        self._recurrent_activation_functions = None
        self._max_epoch = None
        self._validation_split = None
        self._random_seed = None
        self._recurrent_input_count_range = None
        self._engine_config = None
        self.discriminator = None

        if dropout is not None:
            self.dropout = dropout
        if batch_size is not None:
            self.batch_size = batch_size
        if recurrent_dropout is not None:
            self.recurrent_dropout = recurrent_dropout
        if recurrent_output_count is not None:
            self.recurrent_output_count = recurrent_output_count
        if dataset_id is not None:
            self.dataset_id = dataset_id
        if inputs is not None:
            self.inputs = inputs
        if output_ranges is not None:
            self.output_ranges = output_ranges
        if hidden_layer_count_range is not None:
            self.hidden_layer_count_range = hidden_layer_count_range
        if neurons_per_layer is not None:
            self.neurons_per_layer = neurons_per_layer
        if training_algorithms is not None:
            self.training_algorithms = training_algorithms
        if activation_functions is not None:
            self.activation_functions = activation_functions
        if recurrent_activation_functions is not None:
            self.recurrent_activation_functions = recurrent_activation_functions
        self.max_epoch = max_epoch
        self.validation_split = validation_split
        if random_seed is not None:
            self.random_seed = random_seed
        if recurrent_input_count_range is not None:
            self.recurrent_input_count_range = recurrent_input_count_range
        if engine_config is not None:
            self.engine_config = engine_config

    @property
    def dropout(self):
        """Gets the dropout of this KerasRecurrentOptimizationConfig.  # noqa: E501


        :return: The dropout of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :rtype: Range
        """
        return self._dropout

    @dropout.setter
    def dropout(self, dropout):
        """Sets the dropout of this KerasRecurrentOptimizationConfig.


        :param dropout: The dropout of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :type: Range
        """

        self._dropout = dropout

    @property
    def batch_size(self):
        """Gets the batch_size of this KerasRecurrentOptimizationConfig.  # noqa: E501


        :return: The batch_size of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :rtype: int
        """
        return self._batch_size

    @batch_size.setter
    def batch_size(self, batch_size):
        """Sets the batch_size of this KerasRecurrentOptimizationConfig.


        :param batch_size: The batch_size of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :type: int
        """

        self._batch_size = batch_size

    @property
    def recurrent_dropout(self):
        """Gets the recurrent_dropout of this KerasRecurrentOptimizationConfig.  # noqa: E501


        :return: The recurrent_dropout of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :rtype: Range
        """
        return self._recurrent_dropout

    @recurrent_dropout.setter
    def recurrent_dropout(self, recurrent_dropout):
        """Sets the recurrent_dropout of this KerasRecurrentOptimizationConfig.


        :param recurrent_dropout: The recurrent_dropout of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :type: Range
        """

        self._recurrent_dropout = recurrent_dropout

    @property
    def recurrent_output_count(self):
        """Gets the recurrent_output_count of this KerasRecurrentOptimizationConfig.  # noqa: E501


        :return: The recurrent_output_count of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :rtype: int
        """
        return self._recurrent_output_count

    @recurrent_output_count.setter
    def recurrent_output_count(self, recurrent_output_count):
        """Sets the recurrent_output_count of this KerasRecurrentOptimizationConfig.


        :param recurrent_output_count: The recurrent_output_count of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :type: int
        """

        self._recurrent_output_count = recurrent_output_count

    @property
    def dataset_id(self):
        """Gets the dataset_id of this KerasRecurrentOptimizationConfig.  # noqa: E501


        :return: The dataset_id of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :rtype: str
        """
        return self._dataset_id

    @dataset_id.setter
    def dataset_id(self, dataset_id):
        """Sets the dataset_id of this KerasRecurrentOptimizationConfig.


        :param dataset_id: The dataset_id of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :type: str
        """

        self._dataset_id = dataset_id

    @property
    def inputs(self):
        """Gets the inputs of this KerasRecurrentOptimizationConfig.  # noqa: E501


        :return: The inputs of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :rtype: list[InputConfig]
        """
        return self._inputs

    @inputs.setter
    def inputs(self, inputs):
        """Sets the inputs of this KerasRecurrentOptimizationConfig.


        :param inputs: The inputs of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :type: list[InputConfig]
        """

        self._inputs = inputs

    @property
    def output_ranges(self):
        """Gets the output_ranges of this KerasRecurrentOptimizationConfig.  # noqa: E501


        :return: The output_ranges of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :rtype: list[Range]
        """
        return self._output_ranges

    @output_ranges.setter
    def output_ranges(self, output_ranges):
        """Sets the output_ranges of this KerasRecurrentOptimizationConfig.


        :param output_ranges: The output_ranges of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :type: list[Range]
        """

        self._output_ranges = output_ranges

    @property
    def hidden_layer_count_range(self):
        """Gets the hidden_layer_count_range of this KerasRecurrentOptimizationConfig.  # noqa: E501


        :return: The hidden_layer_count_range of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :rtype: Range
        """
        return self._hidden_layer_count_range

    @hidden_layer_count_range.setter
    def hidden_layer_count_range(self, hidden_layer_count_range):
        """Sets the hidden_layer_count_range of this KerasRecurrentOptimizationConfig.


        :param hidden_layer_count_range: The hidden_layer_count_range of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :type: Range
        """

        self._hidden_layer_count_range = hidden_layer_count_range

    @property
    def neurons_per_layer(self):
        """Gets the neurons_per_layer of this KerasRecurrentOptimizationConfig.  # noqa: E501


        :return: The neurons_per_layer of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :rtype: Range
        """
        return self._neurons_per_layer

    @neurons_per_layer.setter
    def neurons_per_layer(self, neurons_per_layer):
        """Sets the neurons_per_layer of this KerasRecurrentOptimizationConfig.


        :param neurons_per_layer: The neurons_per_layer of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :type: Range
        """

        self._neurons_per_layer = neurons_per_layer

    @property
    def training_algorithms(self):
        """Gets the training_algorithms of this KerasRecurrentOptimizationConfig.  # noqa: E501


        :return: The training_algorithms of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :rtype: list[str]
        """
        return self._training_algorithms

    @training_algorithms.setter
    def training_algorithms(self, training_algorithms):
        """Sets the training_algorithms of this KerasRecurrentOptimizationConfig.


        :param training_algorithms: The training_algorithms of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :type: list[str]
        """
        allowed_values = ["SGD", "RMSprop", "Adagrad", "Adadelta", "Adam", "Adamax", "Nadam"]  # noqa: E501
        if not set(training_algorithms).issubset(set(allowed_values)):
            raise ValueError(
                "Invalid values for `training_algorithms` [{0}], must be a subset of [{1}]"  # noqa: E501
                .format(", ".join(map(str, set(training_algorithms) - set(allowed_values))),  # noqa: E501
                        ", ".join(map(str, allowed_values)))
            )

        self._training_algorithms = training_algorithms

    @property
    def activation_functions(self):
        """Gets the activation_functions of this KerasRecurrentOptimizationConfig.  # noqa: E501


        :return: The activation_functions of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :rtype: list[str]
        """
        return self._activation_functions

    @activation_functions.setter
    def activation_functions(self, activation_functions):
        """Sets the activation_functions of this KerasRecurrentOptimizationConfig.


        :param activation_functions: The activation_functions of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :type: list[str]
        """
        allowed_values = ["SoftMax", "Elu", "Selu", "SoftPlus", "SoftSign", "ReLu", "TanH", "Sigmoid", "HardSigmoid", "Linear"]  # noqa: E501
        if not set(activation_functions).issubset(set(allowed_values)):
            raise ValueError(
                "Invalid values for `activation_functions` [{0}], must be a subset of [{1}]"  # noqa: E501
                .format(", ".join(map(str, set(activation_functions) - set(allowed_values))),  # noqa: E501
                        ", ".join(map(str, allowed_values)))
            )

        self._activation_functions = activation_functions

    @property
    def recurrent_activation_functions(self):
        """Gets the recurrent_activation_functions of this KerasRecurrentOptimizationConfig.  # noqa: E501


        :return: The recurrent_activation_functions of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :rtype: list[str]
        """
        return self._recurrent_activation_functions

    @recurrent_activation_functions.setter
    def recurrent_activation_functions(self, recurrent_activation_functions):
        """Sets the recurrent_activation_functions of this KerasRecurrentOptimizationConfig.


        :param recurrent_activation_functions: The recurrent_activation_functions of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :type: list[str]
        """
        allowed_values = ["SoftMax", "Elu", "Selu", "SoftPlus", "SoftSign", "ReLu", "TanH", "Sigmoid", "HardSigmoid", "Linear"]  # noqa: E501
        if not set(recurrent_activation_functions).issubset(set(allowed_values)):
            raise ValueError(
                "Invalid values for `recurrent_activation_functions` [{0}], must be a subset of [{1}]"  # noqa: E501
                .format(", ".join(map(str, set(recurrent_activation_functions) - set(allowed_values))),  # noqa: E501
                        ", ".join(map(str, allowed_values)))
            )

        self._recurrent_activation_functions = recurrent_activation_functions

    @property
    def max_epoch(self):
        """Gets the max_epoch of this KerasRecurrentOptimizationConfig.  # noqa: E501


        :return: The max_epoch of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :rtype: int
        """
        return self._max_epoch

    @max_epoch.setter
    def max_epoch(self, max_epoch):
        """Sets the max_epoch of this KerasRecurrentOptimizationConfig.


        :param max_epoch: The max_epoch of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :type: int
        """
        if max_epoch is None:
            raise ValueError("Invalid value for `max_epoch`, must not be `None`")  # noqa: E501
        if max_epoch is not None and max_epoch > 4294967295:  # noqa: E501
            raise ValueError("Invalid value for `max_epoch`, must be a value less than or equal to `4294967295`")  # noqa: E501
        if max_epoch is not None and max_epoch < 1:  # noqa: E501
            raise ValueError("Invalid value for `max_epoch`, must be a value greater than or equal to `1`")  # noqa: E501

        self._max_epoch = max_epoch

    @property
    def validation_split(self):
        """Gets the validation_split of this KerasRecurrentOptimizationConfig.  # noqa: E501


        :return: The validation_split of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :rtype: float
        """
        return self._validation_split

    @validation_split.setter
    def validation_split(self, validation_split):
        """Sets the validation_split of this KerasRecurrentOptimizationConfig.


        :param validation_split: The validation_split of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :type: float
        """
        if validation_split is None:
            raise ValueError("Invalid value for `validation_split`, must not be `None`")  # noqa: E501
        if validation_split is not None and validation_split > 1.0:  # noqa: E501
            raise ValueError("Invalid value for `validation_split`, must be a value less than or equal to `1.0`")  # noqa: E501
        if validation_split is not None and validation_split < 0.0:  # noqa: E501
            raise ValueError("Invalid value for `validation_split`, must be a value greater than or equal to `0.0`")  # noqa: E501

        self._validation_split = validation_split

    @property
    def random_seed(self):
        """Gets the random_seed of this KerasRecurrentOptimizationConfig.  # noqa: E501


        :return: The random_seed of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :rtype: int
        """
        return self._random_seed

    @random_seed.setter
    def random_seed(self, random_seed):
        """Sets the random_seed of this KerasRecurrentOptimizationConfig.


        :param random_seed: The random_seed of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :type: int
        """

        self._random_seed = random_seed

    @property
    def recurrent_input_count_range(self):
        """Gets the recurrent_input_count_range of this KerasRecurrentOptimizationConfig.  # noqa: E501


        :return: The recurrent_input_count_range of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :rtype: Range
        """
        return self._recurrent_input_count_range

    @recurrent_input_count_range.setter
    def recurrent_input_count_range(self, recurrent_input_count_range):
        """Sets the recurrent_input_count_range of this KerasRecurrentOptimizationConfig.


        :param recurrent_input_count_range: The recurrent_input_count_range of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :type: Range
        """

        self._recurrent_input_count_range = recurrent_input_count_range

    @property
    def engine_config(self):
        """Gets the engine_config of this KerasRecurrentOptimizationConfig.  # noqa: E501


        :return: The engine_config of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :rtype: RecurrentOptimizationEngineConfig
        """
        return self._engine_config

    @engine_config.setter
    def engine_config(self, engine_config):
        """Sets the engine_config of this KerasRecurrentOptimizationConfig.


        :param engine_config: The engine_config of this KerasRecurrentOptimizationConfig.  # noqa: E501
        :type: RecurrentOptimizationEngineConfig
        """

        self._engine_config = engine_config

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.swagger_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, KerasRecurrentOptimizationConfig):
            return False

        return self.__dict__ == other.__dict__

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        return not self == other
